{"cells":[{"cell_type":"markdown","id":"8ec395aa","metadata":{"id":"8ec395aa"},"source":["# 시나리오\n","- 여러 머신러닝 중 가장 좋은 알고리즘을 알아본다.\n","\n","## 정형 데이터와 비정형 데이터\n","- 앞서 진행한 내용에 사용된 데이터들은 <b>정형 데이터(Structured Data)</b>\n","    - 가장 좋은 성능을 내는 것은 앙상블(ensemble) 학습(Tree기반)\n","- 텍스트, 이미지, 영상 등은 <b>비정형 데이터(Unstructured Data)</b>\n","    - 신경망 알고리즘을 사용\n","\n"]},{"cell_type":"markdown","id":"68fd90fd","metadata":{"id":"68fd90fd"},"source":["## 랜덤 포레스트(Random Forest)\n","- 앙상블 학습의 대표적인 모델\n","- 결정 트리를 랜덤하게 생성하여 숲(Forest)를 구성\n","- 숲을 이루는 각 결정트리 모델의 예측 결과를 이용하여 최종 예측을 만듦\n","- 라이브러리마다 조금씩 내부 구현에 차이가 있음\n","\n","## 사이킷 런에서 제공되는 랜덤 포레스트의 동작\n","- 각 트리를 훈련하기 위한 데이터를 랜덤하게 생성\n","![image.png](attachment:image.png)\n","- 부트스트랩(bootstrap) 샘플\n","    - 데이터셋에서 중복을 허용하여 데이터 샘플링 하는 방식(부트스트랩)\n","    - 기본적으로 추출된 샘플은 훈련 세트와 크기(갯수)가 같음\n","    - 각 노드 분할 시 전체 특성에서 일부 특성을 무작위로 골라 최선의 분할을 찾음(전체 특성 개수의 제곱근 개수)\n","    ![image-2.png](attachment:image-2.png)\n","    - 기본적으로 100개의 결정트리를 위와 같은 방식으로 훈련 진행\n","    - 분류일 때는 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측에 사용\n","    - 회귀일 때는 트리의 예측을 평균하여 사용\n","    \n","### 랜덤 포레스트 특징\n","- 랜덤하게 선택한 샘플과 특성을 이용하므로 훈련 세트에 과대적합을 막을 수 있음\n","- 검증 데이터 세트와 테스트 데이터 세트에서 안정적인 성능을 기대할 수 있음\n","- 디폴트 파라미터 값으로도 좋은 결과를 예상할 수 있음"]},{"cell_type":"markdown","id":"61aec940","metadata":{"id":"61aec940"},"source":["## 와인 분류에 RandomForestClassifier 적용"]},{"cell_type":"markdown","id":"22ef2097","metadata":{"id":"22ef2097"},"source":["### 데이터 준비 및 나누기"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tf0Fs0lQoeDk","executionInfo":{"status":"ok","timestamp":1717745897467,"user_tz":-540,"elapsed":20185,"user":{"displayName":"김호준","userId":"07979186950206322979"}},"outputId":"8768f439-9ef8-412b-aec9-a1512811d834"},"id":"Tf0Fs0lQoeDk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"044376b5","metadata":{"id":"044376b5"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","wine = pd.read_csv('/content/drive/MyDrive/NEW/2week/wine_csv_data.csv')\n","\n","data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n","target = wine['class'].to_numpy()\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"45792180","metadata":{"id":"45792180"},"source":["### cross_validate() 함수로 교차 검증 확인"]},{"cell_type":"code","execution_count":null,"id":"27dc58a8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27dc58a8","executionInfo":{"status":"ok","timestamp":1717746785225,"user_tz":-540,"elapsed":4793,"user":{"displayName":"김호준","userId":"07979186950206322979"}},"outputId":"dad16aa5-17df-464c-8d09-bda1b570b33b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9973541965122431, 0.8905151032797809)"]},"metadata":{},"execution_count":3}],"source":["from sklearn.model_selection import cross_validate\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n","scores = cross_validate(rf, X_train, y_train, return_train_score=True, n_jobs=-1)\n","\n","np.mean(scores['train_score']), np.mean(scores['test_score'])"]},{"cell_type":"code","source":["scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UroMPVR3sLOI","executionInfo":{"status":"ok","timestamp":1717746843749,"user_tz":-540,"elapsed":4,"user":{"displayName":"김호준","userId":"07979186950206322979"}},"outputId":"1dd1db1a-0da6-458f-e90c-b62092d4dcb2"},"id":"UroMPVR3sLOI","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'fit_time': array([0.65391731, 0.62707448, 0.62992358, 0.62680936, 0.40382814]),\n"," 'score_time': array([0.04639602, 0.05622745, 0.05972838, 0.05632138, 0.04540896]),\n"," 'test_score': array([0.88461538, 0.88942308, 0.90279115, 0.88931665, 0.88642926]),\n"," 'train_score': array([0.9971133 , 0.99663219, 0.9978355 , 0.9973545 , 0.9978355 ])}"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","id":"a66778e6","metadata":{"id":"a66778e6"},"source":["##### 해석\n","- RandomForestClassifier는 기본적으로 100개의 결정트리 사용\n","- cross_validate()의 return_train_score옵션은 훈련 세트 점수도 반환함(default는 False)\n","- 모델에도 n_jobs=-1, 분류기에도 n_jobs=-1 설정으로 최대한 CPU코어를 활용하여 병렬처리\n","- 점수를 보면 훈련세트에 다소 과대적합으로 보임"]},{"cell_type":"markdown","id":"4fad7ec7","metadata":{"id":"4fad7ec7"},"source":["### 랜덤 포레스트의 매개변수\n","- 랜덤 포레스트는 결정 트리의 앙상블이므로 DecisionTreeClassifier에서 제공하는 주요 매개변수를 모두 제공\n","- critetion, max_depth, max_features, min_samples_split, min_impurity_decrease, min_sample_leaf 등\n","- 결정 트리의 장점인 특성 중요도를 계산함(각 결정 트리의 특성 중요도를 취합한 것)"]},{"cell_type":"code","execution_count":null,"id":"616e8ae7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"616e8ae7","executionInfo":{"status":"ok","timestamp":1717746874375,"user_tz":-540,"elapsed":789,"user":{"displayName":"김호준","userId":"07979186950206322979"}},"outputId":"2cf0c2ce-75c9-4352-c0b8-f5e33f209340"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.23167441, 0.50039841, 0.26792718])"]},"metadata":{},"execution_count":5}],"source":["# 랜덤 포레스트 모델을 훈련세트로 훈련한 후 특성 중요도 확인\n","rf.fit(X_train, y_train)\n","rf.feature_importances_"]},{"cell_type":"markdown","id":"4ed0ad9d","metadata":{"id":"4ed0ad9d"},"source":["##### 이전 특성 중요도 결과와 비교\n","- 결정트리에서 특성 중요도(['alcohol', 'sugar', 'pH'])\n","    - array([0.12345626, 0.86862934, 0.0079144 ])\n","- 랜덤포레스트에서 특성 중요도\n","    - array([0.23167441, 0.50039841, 0.26792718])\n","    \n","    \n","- 두 번째 특성(sugar)의 중요도가 감소\n","- 알콜도수와 pH의 중요도가 약간 상승\n","- 랜덤 포레스트는 특성의 일부를 랜덤하게 선택하여 결정트리를 훈련하기 때문\n","- 하나의 특성에 집중하지 않고 더 다양한 특성이 훈련에 기여하게 됨\n","- 과대적합을 줄이고 일반화 성능을 높이는 것을 도움"]},{"cell_type":"markdown","id":"9047dada","metadata":{"id":"9047dada"},"source":["### 랜덤 포레스트의 자체 모델 평가 점수\n","- 랜덤 포레스트는 훈련 세트에서 중복을 허용하여 부트스트랩 샘플을 생성하고 결정트리를 훈련\n","- 부트스트랩 샘플에 선택되지 않은 나머지 샘플이 있음. ( OOB(out of bag) )\n","- OOB를 이용하여 부트스트랩 샘플로 훈련한 결정 트리를 평가할 수 있음(검증 세트 개념)\n","- RandomForestClassifier클래스의 oob_score매개변수를 True로 지정(기본값 False)\n","- 각 결정트리의 OOB점수를 평균하여 반환"]},{"cell_type":"code","execution_count":null,"id":"1401551b","metadata":{"id":"1401551b","outputId":"c38b1dea-bfa3-41ac-aea7-145e0ec650de"},"outputs":[{"data":{"text/plain":["0.8934000384837406"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# 새로운 랜덤포레스트 객체를 이용하여 oob_score 확인\n","rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n","\n","rf.fit(X_train, y_train)\n","rf.oob_score_"]},{"cell_type":"markdown","id":"e1617a95","metadata":{"id":"e1617a95"},"source":["##### 결과\n","- 교차검증으로 얻었던 결과: 0.8574181117533719\n","- OOB점수를 사용하면 교차검증을 대신할 수 있어 결과적으로 훈련 세트로 더 많은 샘플 이용가능"]},{"cell_type":"markdown","id":"6d3a5660","metadata":{"id":"6d3a5660"},"source":["## 엑스트라 트리(Extra Trees)\n","- 기본적으로 랜덤포레스트와 비슷하게 동작\n","- 100개의 결정 트리 훈련\n","- 결정 트리에서 제공하는 대부분의 매개변수 지원\n","- 전체 특성 중 일부 특성을 랜덤하게 선택하여 노드 분할에 사용\n","\n","### 차이점\n","- 부트스트랩 샘플을 사용하지 않고 전체 훈련 세트를 무작위로 사용\n","\n","### 특징\n","- 결정트리의 매개변수 중 splitter='random'으로 설정 했을 때 사용하는 결정 트리가 엑스트라 트리\n","- 하나의 결정 트리에서 특성을 무작위로 분할 하면 성능이 낮아질 수 있음\n","- 많은 트리를 앙상블하여 진행하므로 과대적합을 막고 검증 세트의 점수를 높이는 효과가 있음\n","- 사이킷-런에서 제공하는 ExtraTreesClassifier(회귀를 하려는 경우 ExtraTreesRegressor)"]},{"cell_type":"code","execution_count":null,"id":"35487505","metadata":{"id":"35487505","outputId":"bd4fdb79-5473-4864-9669-91815e82026d"},"outputs":[{"data":{"text/plain":["(0.9974503966084433, 0.8887848893166506)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# ExtraTreesClassifier를 적용하여 교차 검증 점수 확인\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n","scores = cross_validate(et, X_train, y_train, return_train_score=True, n_jobs=-1)\n","\n","np.mean(scores['train_score']), np.mean(scores['test_score'])"]},{"cell_type":"markdown","id":"19aa0249","metadata":{"id":"19aa0249"},"source":["##### 결과\n","- 랜덤 포레스트의 결과: (0.9973541965122431, 0.8905151032797809)\n","- 특성이 많지 않아서 두 모델의 차이가 크지 않음\n","- 일반적으로 엑스트라 트리가 무작위성이 높아서 랜덤 포레스트보다 더 많은 결정트리를 훈련하게 됨\n","- 많은 트리를 훈련하지만 랜덤하게 노드를 분할 하므로 빠른 계산 속도가 엑스트라 트리의 장점\n","- 결정 트리는 최적의 분할을 찾는데 시간 소모가 많음(고려할 특성 개수가 많으면 더 많아짐)"]},{"cell_type":"code","execution_count":null,"id":"7e7ef22a","metadata":{"id":"7e7ef22a","outputId":"8fc0745c-a589-47f1-ab36-4becd419df29"},"outputs":[{"data":{"text/plain":["array([0.20183568, 0.52242907, 0.27573525])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# 특성 중요도 확인\n","et.fit(X_train, y_train)\n","et.feature_importances_"]},{"cell_type":"markdown","id":"b4769852","metadata":{"id":"b4769852"},"source":["##### 결과\n","- 결정트리에서 특성 중요도(['alcohol', 'sugar', 'pH'])\n","    - array([0.12345626, 0.86862934, 0.0079144 ])\n","- 랜덤 포레스트에서 특성 중요도\n","    - array([0.23167441, 0.50039841, 0.26792718])\n","- 엑스트라 트리에서 특성 중요도\n","    - array([0.20183568, 0.52242907, 0.27573525])\n","- 결정트리보다 당도에 대한 의존성 낮아짐(랜덤 포레스트 결과와 비슷)"]},{"cell_type":"markdown","id":"d0cee9b6","metadata":{"id":"d0cee9b6"},"source":["## 그레이디언트 부스팅(Gradient boosting)\n","- 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블 진행\n","- 사이킷-런에서 제공하는 GradientBoostingClassifier는 기본적으로 깊이가 3인 결정트리를 100개 사용\n","- 깊이가 얕은 트리를 사용하기 때문에 과대적합 확률이 낮아 일반화 성능이 높을 것을 기대\n","- 내부 동작은 경사하강법을 이용하여 트리를 앙상블에 추가함(깊이가 낮은 트리를 이용하는 이유)\n","- 분류 시 로지스틱 손실 함수 사용\n","- 회귀 시 평균 제곱 오차 함수 사용\n","- 학습률 매개변수를 이용하여 경사하강 속도 조절\n","\n","\n","- 일반적으로 랜덤 포레스트보다 조금 더 높은 성능을 얻을 수 있음\n","- 순서대로 트리를 추가하므로 훈련 속도가 다소 느림\n","- n_jobs 매개변수가 없음\n","- 회귀를 하려는 경우 GradientBoostingRegressor 사용"]},{"cell_type":"code","execution_count":null,"id":"cdaa0a32","metadata":{"id":"cdaa0a32","outputId":"aec1d5ec-735e-4321-8c03-ab5b746a0c43"},"outputs":[{"data":{"text/plain":["(0.8881086892152563, 0.8720430147331015)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# GradientBoostingClassifier 사용\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","gb = GradientBoostingClassifier(random_state=42)\n","scores = cross_validate(gb, X_train, y_train, return_train_score=True, n_jobs=-1)\n","\n","np.mean(scores['train_score']), np.mean(scores['test_score'])"]},{"cell_type":"markdown","id":"dc871711","metadata":{"id":"dc871711"},"source":["##### 결과\n","- 과대적합이 거의 없음\n","- 결정 트리의 개수를 늘려도 과대적합 가능성이 낮음"]},{"cell_type":"code","execution_count":null,"id":"b80fb05a","metadata":{"id":"b80fb05a","outputId":"e48711e8-5dc5-4202-daa6-2137e949fcd8"},"outputs":[{"data":{"text/plain":["(0.9464595437171814, 0.8780082549788999)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# 트리 개수와 학습률을 조정하여 학습\n","gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n","scores = cross_validate(gb, X_train, y_train, return_train_score=True, n_jobs=-1)\n","\n","np.mean(scores['train_score']), np.mean(scores['test_score'])"]},{"cell_type":"markdown","id":"cf7d875a","metadata":{"id":"cf7d875a"},"source":["##### 결과\n","- 학습률 0.2 (디폴트 0.1)\n","- 트리의 개수 500\n","- 트리의 개수를 늘린 것에 비해 과대적합이 어느정도 제어되고 있음"]},{"cell_type":"code","execution_count":null,"id":"6d91ba9f","metadata":{"id":"6d91ba9f","outputId":"e328180e-3fc8-44da-bea6-772fa7eafa41"},"outputs":[{"data":{"text/plain":["array([0.15872278, 0.68011572, 0.16116151])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# 특성 중요도 확인\n","gb.fit(X_train, y_train)\n","gb.feature_importances_"]},{"cell_type":"markdown","id":"2dc48b03","metadata":{"id":"2dc48b03"},"source":["##### 결과\n","- 결정트리에서 특성 중요도(['alcohol', 'sugar', 'pH'])\n","    - array([0.12345626, 0.86862934, 0.0079144 ])\n","- 랜덤 포레스트에서 특성 중요도\n","    - array([0.23167441, 0.50039841, 0.26792718])\n","- 엑스트라 트리에서 특성 중요도\n","    - array([0.20183568, 0.52242907, 0.27573525])\n","- 그레이디언트 부스팅에서 특성 중요도\n","    - array([0.15872278, 0.68011572, 0.16116151])\n","\n","- 랜덤 포레스트나 엑스트라 트리보다 당도에 대한 의존성이 조금 높음\n","\n","#### 해보기\n","- subsample매개변수를 이용하여 확률적 경사하강법 또는 미니배치 경사하강법과 비슷한 효과 적용 가능\n","- subsample=1.0 디폴트.\n","- 1보다 작으면 훈련 세트의 일부분을 사용"]},{"cell_type":"markdown","id":"e61b5935","metadata":{"id":"e61b5935"},"source":["## 히스토그램 기반 그레이디언트 부스팅(Histogram-based Gradient boosting)\n","- 정형 데이터를 다루는 머신러닝 알고리즘 중에 많이 사용되는 알고리즘\n","- 입력 특성을 256개의 구간으로 나누어서 진행\n","- 나눈 구간 중 하나의 구간은 누락된 값을 위해 사용(전처리 진행 불필요)\n","- 노드 분할 시 최적의 분할을 빠르게 찾음\n","- 사이킷-런에서 제공되는 HistGradientBoostingClassifier 사용\n","- 트리 개수 지정에 n_estimators가 아닌 max_iter사용(성능을 높이고자 할 경우 활용)"]},{"cell_type":"code","execution_count":null,"id":"9f268db2","metadata":{"id":"9f268db2","outputId":"39bd2ab8-c05d-4d1e-f65c-6dab631da183"},"outputs":[{"data":{"text/plain":["(0.9321723946453317, 0.8801241948619236)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# 사이킷런 1.0 버전 아래에서는 다음 라인의 주석을 해제하고 실행\n","# from sklearn.experimental import enable_hist_gradient_boosting\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","\n","hgb = HistGradientBoostingClassifier(random_state=42)\n","scores = cross_validate(hgb, X_train, y_train, return_train_score=True, n_jobs=-1)\n","\n","np.mean(scores['train_score']), np.mean(scores['test_score'])"]},{"cell_type":"markdown","id":"8f2d14ed","metadata":{"id":"8f2d14ed"},"source":["##### 결과\n","- 과대적합을 억제하면서 그레이디언트 부스팅보다 약간 더 높은 성능 제공"]},{"cell_type":"markdown","id":"291b171b","metadata":{"id":"291b171b"},"source":["### 특성 중요도 확인(permutation_importance() 사용)\n","- 특성을 하나씩 랜덤하게 섞어 모델의 성능이 변화하는지 관찰하며 어떤 특성이 중요한지 계산함\n","- 훈련세트 및 테스트 세트에도 적용가능하며 사이킷-런의 추정기 모델에 모두 사용 가능\n","- n_repeats: 랜덤하게 섞을 횟수(디폴트: 5)\n","- 반환 객체는 다음 내용을 담고 있음\n","    - importances: 반복 작업을 통해 얻은 특성 중요도\n","    - importances_mean: 평균\n","    - importances_std: 표준편차"]},{"cell_type":"code","execution_count":null,"id":"2511b304","metadata":{"id":"2511b304","outputId":"434dccb3-c65b-40f4-c6ba-f951eb14ea1c"},"outputs":[{"data":{"text/plain":["array([0.08876275, 0.23438522, 0.08027708])"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# 훈련 세트의 특성 중요도\n","from sklearn.inspection import permutation_importance\n","\n","hgb.fit(X_train, y_train)\n","result = permutation_importance(hgb, X_train, y_train, n_repeats=10,\n","                                random_state=42, n_jobs=-1)\n","result.importances_mean"]},{"cell_type":"code","execution_count":null,"id":"cb532074","metadata":{"id":"cb532074","outputId":"083facf7-a6c8-4d4c-fd5d-0f81cd64c7e8"},"outputs":[{"data":{"text/plain":["array([0.05969231, 0.20238462, 0.049     ])"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["# 테스트 세트의 특성 중요도\n","result = permutation_importance(hgb, X_test, y_test, n_repeats=10,\n","                                random_state=42, n_jobs=-1)\n","result.importances_mean"]},{"cell_type":"markdown","id":"d627259f","metadata":{"id":"d627259f"},"source":["##### 결과\n","- 히스토그램 기반 그레이디언트 부스팅도 그레이디언트 부스팅과 비슷하게 당도에 집중\n","- 실제 분석에 모델이 사용될 경우 어떤 특성에 관심이 높은지 예상 가능함"]},{"cell_type":"code","execution_count":null,"id":"df0eb735","metadata":{"id":"df0eb735","outputId":"99cd4ad6-7cf2-403f-a12a-a1644720b523"},"outputs":[{"data":{"text/plain":["0.8723076923076923"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# 테스트 세트로 최종 성능 확인\n","hgb.score(X_test, y_test)"]},{"cell_type":"markdown","id":"953820dc","metadata":{"id":"953820dc"},"source":["##### 결과\n","- 테스트 세트에서 약 87%의 정확도를 보임(실전에 사용하면 다소 낮아질 것임)\n","- 앙상블이 단일 결정트리보다 좋은 결과를 얻을 수 있음\n","- 그레이디언트 부스팅 알고리즘을 구현한 다른 라이브러리\n","    - XGBoost\n","        - cross_validate()와 함께 사용 가능\n","        - tree_method='hist'로 지정하면 히스토그램 기반 그레이디언트 부스팅 사용 가능\n","\n","    - LightGBM\n","        - 마이크로소프트에서 만든 라이브러리\n","        - 빠르고 최신 기술이 많이 적용되어 있음\n","        - 히스토그램 그레이디언트 부스팅에 가장 영향을 많이 줌"]},{"cell_type":"markdown","id":"0a000278","metadata":{"id":"0a000278"},"source":["## 그 외의 라이브러리\n","- XGBoost\n","- LightGBM"]},{"cell_type":"code","execution_count":null,"id":"49edd01e","metadata":{"id":"49edd01e","outputId":"93bc9a7a-c5d5-4237-a600-1a42ad16cdea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting xgboost==0.90\n","  Downloading xgboost-0.90-py2.py3-none-win_amd64.whl (18.3 MB)\n","Requirement already satisfied: scipy in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from xgboost==0.90) (1.7.3)\n","Requirement already satisfied: numpy in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from xgboost==0.90) (1.21.5)\n","Installing collected packages: xgboost\n","Successfully installed xgboost-0.90\n"]}],"source":["# 설치가 안되어 있는 경우 설치 진행\n","#!pip install xgboost==0.90"]},{"cell_type":"code","execution_count":null,"id":"346c6179","metadata":{"scrolled":true,"id":"346c6179","outputId":"39bb95d1-1976-4502-b6bb-ce38bfd16ad7"},"outputs":[{"data":{"text/plain":["(0.8824322471423747, 0.8726214185237284)"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["# XGBoost 사용 예제\n","from xgboost import XGBClassifier\n","\n","xgb = XGBClassifier(tree_method='hist', random_state=42)\n","scores = cross_validate(xgb, X_train, y_train, return_train_score=True, n_jobs=-1)\n","\n","np.mean(scores['train_score']), np.mean(scores['test_score'])"]},{"cell_type":"code","execution_count":null,"id":"bd711775","metadata":{"id":"bd711775","outputId":"df0d4ec1-6a05-4a37-edc5-20c18dd190b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting lightgbm\n","  Downloading lightgbm-3.3.3-py3-none-win_amd64.whl (1.0 MB)\n","Requirement already satisfied: wheel in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n","Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n","Requirement already satisfied: scipy in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n","Requirement already satisfied: numpy in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n","Requirement already satisfied: joblib>=0.11 in c:\\users\\itthi\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n","Installing collected packages: lightgbm\n","Successfully installed lightgbm-3.3.3\n"]}],"source":["# LightGBM 설치\n","#!pip install lightgbm"]},{"cell_type":"code","execution_count":null,"id":"2c6e4cc8","metadata":{"id":"2c6e4cc8","outputId":"7c7a6686-c7a1-4e7e-faec-fc49b8fa4c9e"},"outputs":[{"data":{"text/plain":["(0.935828414851749, 0.8801251203079884)"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# LightGBM 사용 예제\n","from lightgbm import LGBMClassifier\n","\n","lgb = LGBMClassifier(random_state=42)\n","scores = cross_validate(lgb,  X_train, y_train, return_train_score=True, n_jobs=-1)\n","\n","np.mean(scores['train_score']), np.mean(scores['test_score'])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}